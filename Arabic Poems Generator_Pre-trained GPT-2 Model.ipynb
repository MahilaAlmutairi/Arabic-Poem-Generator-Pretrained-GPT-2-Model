{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "3f21454b-9f8b-49e4-e64b-2fa0426a1d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUmTooTW3osf",
    "outputId": "a9dc8745-eaed-4938-aa76-f3afa13a9bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  9 11:52:57 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    26W / 250W |      1MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8wSlgXoDPCR",
    "outputId": "081f2554-886c-4f43-d6e0-db280ce53673"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 501Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 124Mit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 789Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 174Mit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 300Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 166Mit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 179Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=\"124M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puq4iC6vUAHc",
    "outputId": "54170f6b-5b56-4014-a4e0-11a1dfeb9e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "gpt2.mount_gdrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixX_bV7XVHYM"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "# Read, then decode for py2 compat.\n",
    "with io. open('/content/sample_data/praise-poems_dataset.txt', 'r',encoding='utf8')as f:\n",
    "   text = f.read()\n",
    "# remove some exteranous chars \n",
    "execluded = '!()/*-.1:=[]«»;؛−,،~?؟#\\u200f\\ufeff'\n",
    "#execluded2 ='\"'\n",
    "#execluded3 =\"'\"\n",
    "out = \"\"\n",
    "\n",
    "for char in text:\n",
    "  if char not in (execluded):\n",
    "    out += char\n",
    "out = out.replace(\"\\t\\t\\t\", \"\\t\")\n",
    "out = out.replace(\"\\r\\r\\n\", \"\\n\")\n",
    "out = out.replace(\"\\r\\n\",\"\\n\")\n",
    "out = out.replace(\"\\t\\n\", \"\\n\")\n",
    "out = out.replace(\"\\n\\n\", \"\\n\")\n",
    "out = out.replace('\"', \"\")\n",
    "out = out.replace(\"'\", \"\")\n",
    "\n",
    "# process Unicode text\n",
    "with io.open('/content/sample_data/try2.txt', 'w', encoding='utf8') as f:\n",
    "    f.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0SqrmI-FWOJ"
   },
   "source": [
    "## Finetune GPT-2\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`.\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps and when the cell is stopped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5gidV7MXLfn"
   },
   "outputs": [],
   "source": [
    "file_name = \"/content/sample_data/try2.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "d3ef0248-6f82-42b6-9ac9-e001c0674aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 1242469 tokens\n",
      "Training...\n",
      "[50 | 68.54] loss=1.86 avg=1.86\n",
      "[100 | 130.76] loss=1.72 avg=1.79\n",
      "[150 | 192.97] loss=1.75 avg=1.78\n",
      "[200 | 255.09] loss=1.74 avg=1.77\n",
      "======== SAMPLE 1 ========\n",
      " السلك\n",
      "أبوادع فيهِ من شرّ اللّه والمّبعُ\n",
      "فبغيثٍ تارف دونان ععمها إذا شرٌ\n",
      "زاءق سهاد فيهِ دونان الفعمة\n",
      "وتمّ الإجخاء قبل الأبيصة بني\n",
      "خَصفارَ الماء الصفرِ سَرافعي أكراماما\n",
      "بتمصُّوت لمل هواء عززُه\n",
      "ويامس سولَ الرجمِ الغداث ماؤكاما\n",
      "في المغزائيش والعداث السُوافُ الفعمام\n",
      "ام يُناري بنشرٍ إنت تني الرجمة\n",
      "هَتلاَ منُ فتندُه بالمراحُ الفعمام\n",
      "فلي والعُدتِ في لام تَنجِعن قُلبه\n",
      "قلما جروب الغُراب الوتاب بناما\n",
      "فما يقصاع العليم والمعراةِ الفعمام\n",
      "فيَسعُ غيرها إذعاني بترقُقُ\n",
      "قَفت تجهري مَن شهرغ بها الصيم\n",
      "بُرجٌ الوجورة عقباتٌ بقائم\n",
      "بِمُحتُ الزهرِقين يفرى د دَدَنا\n",
      "إذا عندَ سَعمُ المُهّيرةَ ليَّتَنا\n",
      "ريكان مَعُي لرَغير المجدادِ قات قوم\n",
      "عَرضٌ عند العارِ الذيود عزال مليك لمجرا\n",
      "فَدُ سابرانَ المُزابِرهُ للحسنا بن\n",
      "ظالرٌ عَلى من الرجم أرية الإرمام\n",
      "هام هاروٌ وفيه الرجم والعِرابتَ بن\n",
      "باعث لا قُلوم من كرأة بِفايم\n",
      "عليٌ عند التَوراحِ الدَّغم المندي بِأوم\n",
      "في ارد اقْولَها غيرا الجَمالِ قد برام\n",
      "شرمٌ عوٍ عكر الرفوك شرى الفرمُ فعام\n",
      "فيهَ الرقيض لا نُسوق لي الإهم مليك لنَضى\n",
      "وسليمةَ حلّوظه عيدُ القومة\n",
      "\n",
      "[250 | 327.08] loss=1.75 avg=1.76\n",
      "[300 | 389.17] loss=1.58 avg=1.73\n",
      "[350 | 451.21] loss=1.43 avg=1.69\n",
      "[400 | 513.31] loss=1.55 avg=1.67\n",
      "======== SAMPLE 1 ========\n",
      "�بة ورائثه\n",
      "؆فسرانة جتويةً البيض رأسي\n",
      "املام من عَدَل لا أنتَ نَفسى\n",
      "ٍ للمصبر أهلي لا خوضه\n",
      "ولم إن لها آفافيها شرقي\n",
      "وقد هو الهذا يعظفى له ورضى\n",
      "وإن تغرف عن للمُعِّزَ الدعى\n",
      "لنها بذاك يفقره نعري\n",
      "وقد هبيته خلى الخيرِ وصدى\n",
      "وأذو سوف عن سيرة\n",
      "جمعاقي وأبله يفضى\n",
      "كنال كمالً له شُكاهرهم\n",
      "صحانانه يُنصحُ عند الرَّمى\n",
      "وفيه آباسهم والله شكفى\n",
      "لَهٌ إلى المشقى شُبَّته الأعمى\n",
      "سلامة قليل فحرفي وة\n",
      "ألحُ فضلٍ لو يخيرٍ والبيضى\n",
      "وابْناً من خاطي غادةً\n",
      "ورضُّ يرى القراشةً والأبس\n",
      "فادتها بقنا كريماً\n",
      "فلعثن إحبةٍ لي سورفِ\n",
      "فصلافه ساً وشومها صخرَ\n",
      "ومدرك لي أعياه والسيمى\n",
      "تُ كبر أفيحُنَّت سجيلٍ\n",
      "أنسها شُؤْثلاً منه كلال الأبعى\n",
      "يماه شُؤْثلاً تخفُّرُها\n",
      "وحكل الحبر الشَّهر منه\n",
      "يبِسات من حُبرَّتكة\n",
      "صدَقَت على اللها زيائرا\n",
      "عنونَ ماجلَثي الإحلام أو البدى\n",
      "غير إما عاءنَ عنيها وغلى\n",
      "وقاءَ من مباندَها اتتتتهفَّى\n",
      "واحتذُ باقرق الإخاروه\n",
      "ويثر الدنيا سباه والأبوسِ\n",
      "صداً مقولٍ منه لم يثن\n",
      "وصداً منَّه وإن حقّاً\n",
      "حفيقٌ عُشمَ أهل يمعودٌ\n",
      "نيلاً والله في الكنود\n",
      "نويلُ خش\n",
      "\n",
      "[450 | 584.12] loss=1.70 avg=1.67\n",
      "[500 | 646.22] loss=1.45 avg=1.65\n",
      "Saving checkpoint/run1/model-500\n",
      "[550 | 710.70] loss=1.60 avg=1.64\n",
      "[600 | 772.77] loss=1.41 avg=1.62\n",
      "======== SAMPLE 1 ========\n",
      "�ولَت حِرَّةً بِقَوْمِي سَلِيُّهَمْ\n",
      "مِنَ الْقَبْلِ بِبَدادِيَهَمْ\n",
      "يَخْطَى خَطِكةً مِنْ تَنِيْجِهَمْ\n",
      "وَلَدَوْ بِدَوْرِ الْقَوَيْقِ حِجُّهَمْ\n",
      "وَرَفَْعَ الْفَمَانِي عُودَ بِكَفِّهَمْ\n",
      "فَضْلَ مِنَ الْمَعُودِ الْعَوَتِّ سَلِيُّهَمْ\n",
      "أَهَتْبُ فِتحَ حَبْلَ الْعِزِيِّ بُودَتْ\n",
      "يُزَمُّ الثَّلاءَ مِنَ الْعِصافَ قَمْ\n",
      "ثُودَكَ كَمَا حِرَّةٌ عِنْدِيَهَمْ\n",
      "يَغْنى مَادِي يَغْنى عِنْدَ بِكَفِّهَمْ\n",
      "فَجْرِكَ يَثُودَكَ مِنْكَ حِجَةً مَدْ\n",
      "رَارَةً هَذَاهَا حِجَةً نَجَمْ\n",
      "صَيْبِرٌ لا مَعْقودَكَ حِجَةً مَمْ\n",
      "خَيْرِكَ بِعَدْقٍ لَكَ حِجَةٍ مَحْ\n",
      "ريحُ قَوَى دُرْعَانا بِجَوْهَمْ\n",
      "غَدَا عارِدَ الْغِطايا رُدَعَتْ\n",
      "صَوِّقَا أَنَامَ بَنِيَّةَ صَوَّةٍ\n",
      "عَمَى مِنَ الحَبِيِّ لَكَ أَثَرَا\n",
      "فُتَقاوَتْ عَنْ فِتَقْتِ الْعُوَدُ وَاِرْتَلَمْ\n",
      "تَهَنَّما عَلَى التَّقَامِ مَتْنَى إِلى\n",
      "مَتْنِهَا بِرِئِيْنِيَكَ مِثْلَ حِجَمْ\n",
      "هَافِرْنَا لَمْطَعْتَهَا وَاِبْتَظَتْنَةَ\n",
      "فِيْحَمَ أَبْسَى نَجَاجِعُهَا وَتَصَّمْ\n",
      "إِنَّ الْبَدَائِقَ بِالْجَزْرِيِّ رَبْشَةً\n",
      "تَرُوَّى إِلَّا فِيْ\n",
      "\n",
      "[650 | 843.93] loss=1.49 avg=1.61\n",
      "[700 | 905.98] loss=1.46 avg=1.60\n",
      "[750 | 968.04] loss=1.43 avg=1.59\n",
      "[800 | 1030.09] loss=1.56 avg=1.59\n",
      "======== SAMPLE 1 ========\n",
      "�ٍ\n",
      "ماصمُ بهم من يشبو متبقى\n",
      "بحزرِ سهامُ وعجَلٍ لاوبدٌ\n",
      "لو كان همامُ ووقطَ تبوقى\n",
      " جودُ اللوابنِ حرماً وثمهم\n",
      "فصبحُ الصول حرماً وقاشدٌ\n",
      "ذو مُرجَعةِ الخلقِ وخبتَني\n",
      "في عبد صياباً من الخبَلِ\n",
      "أحزامُ من أسيرٍ لها وسُقى\n",
      "من يعطفون بثيابَها تخفّيه\n",
      "ويوماً بلا من فضائر توائحٌ\n",
      "فإن وأثاهُ من علم عافونٍ\n",
      "ذوي الغريات وحفّيَةَ الحرِّ\n",
      "من مسّاخٍ نقر طباها بلخفةٌ\n",
      "كلُّ دؤوسٍ سوى الحرب قتلنا\n",
      "ويزيدُ ما أوثار ؃لّ شفارِه\n",
      "لأكونِ الدنيا المآلُ خلافَةً\n",
      "فخفّتي ربقٍ ذهبٍ أسبهافِه\n",
      "وفي الطلّيدَ إليك أبيتيك الزعْفَ\n",
      "ثم وأيهالك للناس بعيشها\n",
      "لما ثقَّ على المبطار المثلِها\n",
      "باللّئين وبالمسائر شمسافِه\n",
      "مإقليلٌ أباً لسان عنِ العَرافِه\n",
      "تقدّها من كلّ إليه ظليمَها\n",
      "وإذا امرؤ شهدٌ شهدٌ قضضى\n",
      "ستخلّقُ ما إن شكرك من كرفِه\n",
      "نافوسُ بنبين ونافوسُ كلُّوانُه\n",
      "فلكني خير العيش ذلّها الغرفِه\n",
      "فما جاهَ ضُلوعاها خير ثعلا\n",
      "ترى الآراء إلا اقفَظَ الختصفِه\n",
      "فلم يوماً لا يظل عنك أسوافةً\n",
      "لا في اللّاح يا أظل ورّتُ المعرف\n",
      "ولهفا ولا بقيت إلا مِذاقَها\n",
      "فارق حظّ ذكريّاً ولا مَ\n",
      "\n",
      "[850 | 1100.97] loss=1.22 avg=1.56\n",
      "[900 | 1163.03] loss=1.59 avg=1.57\n",
      "[950 | 1225.08] loss=1.35 avg=1.55\n",
      "[1000 | 1287.12] loss=1.35 avg=1.54\n",
      "Saving checkpoint/run1/model-1000\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 1 ========\n",
      " اللَّه\n",
      "ليس مديح مثل ما غدا\n",
      "فالعُباب مستقم ثاول\n",
      "فقد اإنت أجمعتْ زغائرْ\n",
      "لم يوحق بالمُقاصبِمِ\n",
      "وما أيدُك يا أين الشاي\n",
      "في الشعرة والشعرةْ\n",
      "إن نفس الضرحَ ذي همّا\n",
      "رَمّتِ القتل والمُطْرَمِ\n",
      "ألوهُ المجدْ كان الندى\n",
      "أنت مع القنا والجنيمِ\n",
      "ومجد وارقِ الذي تكون\n",
      "ما أسمعْت معاق الدَّمي\n",
      "أيما ثاوتُها أشاقٍ\n",
      "في جدوةٍ من أسمي\n",
      "أيها الصغايؤُ تشغون\n",
      "فأيها السمعُ تمقي\n",
      "وأيها البنادُ تبدون\n",
      "لَعلُ بكنَّ من ليَ ال\n",
      "له ممو أين إلى عَرَمِ\n",
      "فأوقاث الألساج تراإينه\n",
      "يها كاذرمٌ بافدر مزمين\n",
      "كتدبرٌ من قال في لم تفنس\n",
      "إليه المجد فليت له الآنِسين\n",
      "منه غيره ولم يدإ\n",
      "من ليس وثاق له المطرى ثاوينه\n",
      "عليه مصلوا وعلك المأْوِبين\n",
      "مت عمهم يا إذ يمْني الذي\n",
      "أخو الضعوز لم يهز بلونْ\n",
      "من خنَّج البياض مُنصمينه\n",
      "لم كنْ شلك آل المونَ ذُلَّنا\n",
      "فيحجبه من وفاءِ البأس العميننا\n",
      "الإسوانا من أحواله جلونُوا\n",
      "كما كان أيامه قُلوبُ الخلقَنا\n",
      "لقد أمُلَّ ذي نني الكل افعلنا\n",
      "الإنسانُ والفؤادُ تخلوننا\n",
      "لفؤاده بالنفوسِ إذا أنت ذكا\n",
      "ديت عني أبو السياء ترقَّنينا\n",
      "بعد لم يوله مفرجهنْ بسَندْ\n",
      "اسألى فما كان فضل بغادٍ\n",
      "لعاشٍ لا لدَهْم الدَّم الخلق بنفق\n",
      "عليه ف\n",
      "\n",
      "[1050 | 1360.08] loss=1.39 avg=1.53\n",
      "[1100 | 1422.17] loss=1.56 avg=1.53\n",
      "[1150 | 1484.23] loss=1.28 avg=1.52\n",
      "[1200 | 1546.34] loss=1.25 avg=1.51\n",
      "======== SAMPLE 1 ========\n",
      "ِفَة الأُفقِ\n",
      "تَمِعُ النيلَ لَم يُلهَمهُ\n",
      "هَل يَوماً لِلسينِ وَيَغطُمه\n",
      "حَسَبُ الشُدورِ وَتابُهُ السَري\n",
      "وَحسبُه لِنِعمِ الشِدا اِمتِظامِ مَورِهِ\n",
      "وَفي الوَءِ في يَكبِسهِ عَلِمتو\n",
      "مَن لا مَجدٍ أَعطَتِ البَحرَ مَن يَسُمِ\n",
      "وَقُدَّتكَ بِهِ مِن واحِشِ الشَطامِ\n",
      "فَكانَا بِهِ يا شَكَّ يَندي\n",
      "كَانَت فَمَن يَقومُ بَعدَهُ أَمرَهِ\n",
      "بِتَفاضِرِنِيَاضِ البَلغاتِ\n",
      "تَذُلُّ الرِجالَ ظِلّاً وَقُلنا ال\n",
      "رَفَعِ وَلافَي العَطاءَ عُيوفَتِ\n",
      "لِكُلِّ يا قِصبُ اللَذةِ فيهِ السُبرِ\n",
      "لَولاهُ يُجِئنَ مِن حَليمِ الرِوامِ\n",
      "رُغماتُ مِناكَ لَم تُجِدِّل ذُراكَ\n",
      "فَمِن جِئنَ كُل جِئنَ الجِدِّ الخَفافِ\n",
      "بِعِزِّكَ مُضرَبٍ كَمِتافَيهِ وَمُحَمَّدِ\n",
      "رُزِقَت مِن مَوضِعِ البَدراً رَونَ مُطرِمِنا\n",
      "وَأَختارُ لَم أَوتِ فَنّي مَعدودُ لَم أَن\n",
      "نطاعَ المَباني إِلى لَبٍ وَسَمَدِ\n",
      "تَمَنَّيتِ حُكلُمَ حُكلٌ بُقٌ هَبهَةٌ\n",
      "وَكَأسُ الهَشَمِ شُكرُها في بَقِ مُطرِمِنا\n",
      "عَلى شَقِّ شَقّي مُقَصِّصٍ غَدُ غَيِّهِ\n",
      "لا الثُرُ خَلقاً والشَمائِلِ مُقَصِّمِنا\n",
      "وَعِندَنا عَلى شَنِّ مَدّ لَنا بِهِ الغِمِّ\n",
      "لا\n",
      "\n",
      "[1250 | 1617.21] loss=1.45 avg=1.51\n",
      "[1300 | 1679.30] loss=1.43 avg=1.50\n",
      "[1350 | 1741.41] loss=1.14 avg=1.49\n",
      "[1400 | 1803.49] loss=1.29 avg=1.48\n",
      "======== SAMPLE 1 ========\n",
      "�ني أو نفعة أو ضيف ذلني\n",
      "لا خير من لحكمي مفعده\n",
      "أصبحت وتجدعته فتبعث\n",
      "ثبط العراة بعطفت عفوافه\n",
      "للدنيا ودعاة زعمتي نفيسي\n",
      "ومرّعة كل اعتصان عكم العصو\n",
      "لتسرطن في ثمرتي منحل\n",
      "غير فلدنا خلعيه يُفدّعه\n",
      "خسق الرضا وقد صفت يكون حُزوا\n",
      "فليس اختارك قومٌ إذ لاعِدي\n",
      "قد ضاف هُم ما كان عن ضموت\n",
      "نشاء لمزر في ناحل بترحوا\n",
      "غباور لا لقص يُقصّن شهوية\n",
      "حتى كنت غير فيما ضئيت\n",
      "أخو حسن حكم ضراء بعسّاه\n",
      "من له غيش بدر فيما دونعه\n",
      "بمعنى وباتٍ غير منصول\n",
      "خدّل وهو من غنير على الخيرين\n",
      "يسحَّن المصطفى المعسفُ المعسفِ\n",
      "وهوواك فاعزت للمثلهم\n",
      "عما كان عن كل بن تفتهم\n",
      "عزيزك عن كل بعد سرواته\n",
      "وشقاءك في أهل كل بقراهِ\n",
      "على ورّع كل نفس نَزاهُ\n",
      "له نكايت وسجد طهور باهِ\n",
      "بمعمرهم دون بعد ذوي الوَرى\n",
      "فهُم وآلُفتهم على طهورهم\n",
      "فقصر الزجاج وهو الثناء المقرَّ\n",
      "بمن نطاه وبين فخر جزاءهم\n",
      "فليس يُقرّ بل ببريّهمهم\n",
      "فجيء معيشها إلى منياه بأبرقُ\n",
      "وجيء معيشها إلى من سناهه رعو\n",
      "يا في الخلاف والخلاف والعارِهم\n",
      "قبل الجراب والمحريف المصرَ\n",
      "جنّوا وذراه الهائم والتوقَّ\n",
      "منهم لم يقر انسان إلى ضعفهم\n",
      "تتنجُّ التباع بالعزم �\n",
      "\n",
      "[1450 | 1874.39] loss=1.38 avg=1.48\n",
      "[1500 | 1936.48] loss=1.35 avg=1.47\n",
      "Saving checkpoint/run1/model-1500\n",
      "[1550 | 2000.70] loss=1.40 avg=1.47\n",
      "[1600 | 2062.77] loss=1.10 avg=1.46\n",
      "======== SAMPLE 1 ========\n",
      "�\n",
      "إِلَيَّ مَحفوفٌ لَم يُصَنَّفُ\n",
      "تَمادِثُ دَرَكُ الرَدى وَما لَمَهُ\n",
      "بَل بِمَنطِقٍ في ذُلَّةٍ أَعمُدُ\n",
      "تَشَوكِيَ كَالشَبابِ اللاحِ وَبالُهُ\n",
      "وَنَخِذُ السَرارِ عَنَقُ الجِسمِ حاشا\n",
      "إِلى جَنَبِ الحَوادِثَ مِدادِها فَتابا\n",
      "وَأَمضى أَولَيتَ مِن رَأيِ غافِلٍ\n",
      "وَلّى فَرَأَت عَلَيكَ قَولُ اَرتِضاحٍ\n",
      "تَعايفَ إِلى عَنكَ بِالناظِفاتِ إِلى وَتائِكٍ\n",
      "فَلا لَقيتُمُ وَلا بَعضَ وَالَّذي أَكامِلُ النَّصِرُ\n",
      "لَهُ فَلِلبِتاتَ الكَلامِ حِكمَةً\n",
      "وَلِلخَوفِ حَرّاتٍ أَجَلَّ الوَلاءِ\n",
      "ُ يَدايكَ تَخرِجُ مِن نَجدِ خِلالِهِ\n",
      "وَيَنخَلُ في إِبريجِ بِخَمسِ إِذطِرُ\n",
      "تُرَفِّرُ البابَ فَتىً دارَ وَنفىً\n",
      "فُحَلَّت لَهُ وَفي قَباءِ الرِفاحِ\n",
      "يُزَخِّرُ أَعلى الرَغمَ المُخافِلُ بَعدَةً\n",
      "وَقَسَمَ الرافِعِ المَولى كَفيفِ أَن رَمى\n",
      "لِلناظِرينَ وَيَلثاهُ إِلّا بَرا\n",
      "عِندَ اللَهُ فَقَد جَدَّ الجَدَّينَ التاري\n",
      "أَقولُ وَهَل يَومَ كُلُّ بَأسٍ جَداهُ\n",
      "دَوائِرُ بِها قَديمَتَينِ كِلاهُ\n",
      "وَلَمّا أُنشِدَتهُ فَلَم يَبقَ عِناهُ\n",
      "أَخَمسَينِ دُرَّ الدُستورِ بِلائِهِ\n",
      "وَدَعنِ أَوتَي\n",
      "\n",
      "[1650 | 2133.53] loss=1.25 avg=1.45\n",
      "[1700 | 2195.58] loss=1.29 avg=1.44\n",
      "[1750 | 2257.61] loss=1.35 avg=1.44\n",
      "[1800 | 2319.64] loss=1.20 avg=1.43\n",
      "======== SAMPLE 1 ========\n",
      "َك أَننَّ مَطالعَةٌ مِن وَتِند.\n",
      "عَجالاً في ارجاهِ وَرَجَّها\n",
      "وَخُطا الدَراقَةَ صاتِباً مَغمودُ\n",
      "مِروَةٌ كُتَنُ الأَيامَةِ فَما\n",
      "غَزاكَ قُداها في أَجلِها القَدِ\n",
      "مَراكَ مِثلُهُ الكَسرارِ ظَعمَت\n",
      "وَرَينا بأَيامَ المَشيبِ هَديدُ\n",
      "يَنأَلُّ أَن وَيَأسُ أَن تاشى\n",
      "بَنوا إِذا أَبصَروا بشَيبِ خَيشٍ\n",
      "وَفي رِعايَةِ الكَفِّ لا عَددودُ\n",
      "وَرَأَيتِ حَيّا عَنِ الأَغلامِ\n",
      "فَمِن فَرعِ أَجرٍ يُعَيّيكَ عَنها\n",
      "تَغيبُ إِلى سَيِّدَةٍ أَديدُ\n",
      "وَمِن خَوفِ بَينَ طَيبَةٍ أَمسِ فَضاءٍ\n",
      "وَأَساسٍ وَأَلقٍ يَسيدُ كُلُّ أُمِّ\n",
      "فَوارِنٍ سَعِدتَ في تَخَلُّقِ إِسعَةٍ\n",
      "وَوَشيفِ مَن مَطوَنٌ وَقِعدَةٌ\n",
      "لَها في قِيابَةٍ وَقُفَّةٍ مِرسَدِ\n",
      "أَخَذَت عَلَيهِ طَليَّ يُبنى فَأَدبٍ\n",
      "كَما في الرُقاتِ وَقَد سارَ رُكنَد١ٍ\n",
      "حَتّى أَخا سُلطانُهُ المَرءُ وَبَدرُها\n",
      "عُلاكَ ٷالُ كَيفَ كَوكَبُ بَدرِ إِلى الهَدى\n",
      "وَلَحظَكَ لا حُسنُ نَظمِنَ بَدرِ أَثرِها\n",
      "فَلِلخَيلِ مَحمودٍ سَعريفَةً ما وَمَدا\n",
      "تَحَجَّبَها الأَنفُسُ في دونِ حَجرِها\n",
      "باِغراضي سِوى طَوقِها واِستَجبَدا\n",
      "وَيَغشو\n",
      "\n",
      "[1850 | 2390.39] loss=1.21 avg=1.42\n",
      "[1900 | 2452.43] loss=1.29 avg=1.42\n",
      "[1950 | 2514.46] loss=1.15 avg=1.41\n",
      "[2000 | 2576.48] loss=0.94 avg=1.40\n",
      "Saving checkpoint/run1/model-2000\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=2000,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=50,\n",
    "              sample_every=200,\n",
    "              save_every=500\n",
    "             \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHdTL8NDbAh3"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pel-uBULXO2L"
   },
   "source": [
    "## Load a Trained Model Checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCcx5u7sbPTD"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fxL77nvAMAX",
    "outputId": "ffe1407f-9ddb-4a74-a7e0-d58c1436f100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-2000\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-2000\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "## Generate Text From The Trained Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "db87d79d-8b7e-4295-fe3e-9a77d4eafa1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مَنِ اِنتَمَنْ يُنادَى فِي شَرِّهِ وَجَهْرِهِ\n",
      "إِذا أَلْقَيْتَ قَوْمٌ فِي قُلْبِهِ وَنَقْبِهِ\n",
      "وَأَمَّا عَلَيْهِ مِنْ خَلْرِهِ وَهْوِ حَقِّهِ\n",
      "مُسْتَحارٍِ لَمْ تُلْهِهِ بِشِعْرِهِ\n",
      "يَفُضِعُهُ عَنْ كِتابِهِ بَنَيْتَهُ\n",
      "بِكُلِّ مَكانِكَ غَيْرُ مِنْهُ ضَمَنْهِ\n",
      "هُوَ الْحِلمُ بَيْنَ يُخْطِفُهُ فَيَضْلُهُ\n",
      "فَكَأَنَّهُ وَمَكْرُمَهُ عِتْبُ الْخَمَنْهِ\n",
      "غَلَبٌ مِنَ الْحُسْنِ أَنْصَدَهُ حِلَلاً\n",
      "فِي الْبَشْرِ ما بِغَيْرِ مُعْتَقِينِ\n",
      "قَدْرُ بِالْمَدَى إِذا ضَمَّهُ أَغَرَّها\n",
      "قَبْضٌ لا الْكَأْسُ بِذاكَ الْمَجْدِ تَعْلَفُ\n",
      "وَأَقْتَلُ مِنْهُ الْغَيْثُ تَحْكِينِ\n",
      "وَلَوْ أَنَّ حَشْواهُ الْحَشا وَأَحْصَدَ\n",
      "تَلْوَحُ وَلا الْكَأسُ الْغَيْثُ تَشْبِينِ\n",
      "وَأَنْصُرُ ما أَمَّلَ الْهَوى تَتْلَعُ\n",
      "بِحَقِّهِ أَيْسَرٌ كَأَنَّ النَّدى\n",
      "أَيْسَرُها يَشْتاقُ الْعِينِ وَيَهْمِني\n",
      "وَلا في الْقَضاءِ لِذُلِّ الْحُسْنِ حُسْرُها\n",
      "فَقَدْ رِيشُ الْحَشا بِها فِي الْقَضاءِ عَليَّةً\n",
      "أَضْمَعُها فِي الْغِنى وَالْعِينِ وَالْهِمَمُ\n",
      "وَأَنْتَ الْحِلمُ مِنْ خَلْقٍ بِعِضَّ\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpr6RD09Woze",
    "outputId": "cb29990a-1c9e-41ee-bb5c-0836d1d5d563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وَأَحسَنُ مِنكَ لَم تَرَ قَطُّ عَيني\n",
      "وَلَم أَجرِ قَومٍ يَخافُ الذُبابَ بِها\n",
      "وَنَزَّهُ مِن حَيثُ لانتِزارُ أَخرَفُ\n",
      "فَكَم بُعدٍ غَيرِ القَولِ فيما خُلِقوني\n",
      "أَنّي لَمعَ التَقديسِ فيما بَرِحَت\n",
      "وَما كانَ في البَيتِ شُربٌ وَأَخيَفُ\n",
      "تَوارَأُ أَنَّهُ عَنِ الأَعمارِ وَحَلَّهُ\n",
      "إِذا حَلَّ قَلبَ المُقَلَّدِ في كَرَمٍ\n",
      "فَأَدعو لا يُرَى بِالدَولَةِ بُعدَكُم\n",
      "وَأَيدُني بِالحَقِّ المُجيرَ بِطَولِهِ\n",
      "وَعَلِم\n"
     ]
    }
   ],
   "source": [
    "generated_text=gpt2.generate(sess,\n",
    "              length=400,\n",
    "              temperature=0.7,\n",
    "              prefix=\"وَأَحسَنُ مِنكَ لَم تَرَ قَطُّ عَيني\",\n",
    "              nsamples=5,\n",
    "              batch_size=5, return_as_list=True\n",
    "              )[0]\n",
    "print(generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2yUHn0zHeC6",
    "outputId": "1e3c88cf-b278-49fd-9747-ec6a6f06e48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34462\n"
     ]
    }
   ],
   "source": [
    "reference_text= open('/content/sample_data/try2.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "verse_Lines=reference_text.splitlines()\n",
    "references=list()\n",
    "for i in range(len(verse_Lines)):\n",
    "    s=(verse_Lines[i].split())\n",
    "    if s :\n",
    "     references.append(s)\n",
    "    \n",
    "print(len(references))\n",
    "                       \n",
    "#----------------------------------------------------------------------\n",
    "#print(type(candidates_text))\n",
    "new_verse_Lines=generated_text.splitlines()\n",
    "candidates=list()\n",
    "for i in range(len(new_verse_Lines)):\n",
    "    s=(new_verse_Lines[i].split())\n",
    "    if s :\n",
    "       candidates.extend(s)\n",
    "#print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMISwAvNHfuO",
    "outputId": "f527b34b-02b7-4e4d-e93c-1e93d72c07b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU scores-Individual 1-gram: 0.654545\n",
      "BLEU scores-Individual 2-gram: 0.111111\n",
      "BLEU scores-Individual 3-gram: 1.000000\n",
      "BLEU scores-Individual 4-gram: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# n-gram individual BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "print('BLEU scores-Individual 1-gram: %f' % sentence_bleu(references, candidates, weights=(1, 0, 0, 0)))\n",
    "print('BLEU scores-Individual 2-gram: %f' % sentence_bleu(references, candidates, weights=(0, 1, 0, 0)))\n",
    "print('BLEU scores-Individual 3-gram: %f' % sentence_bleu(references, candidates, weights=(0, 0, 1, 0)))\n",
    "print('BLEU scores-Individual 4-gram: %f' % sentence_bleu(references, candidates, weights=(0, 0, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmTXWNUygS5E"
   },
   "source": [
    "# LICENSE\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Arabic_Poems_Train a GPT-2 Text-Generating Model w/ GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
